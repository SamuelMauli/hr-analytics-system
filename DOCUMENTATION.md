# Documenta√ß√£o T√©cnica - Sistema de HR Analytics

## Sum√°rio Executivo

O Sistema de HR Analytics √© uma solu√ß√£o completa e end-to-end para an√°lise de dados de Recursos Humanos, com foco em previs√£o de rotatividade de funcion√°rios (employee attrition) e aloca√ß√£o estrat√©gica de recursos. O sistema implementa as melhores pr√°ticas da ind√∫stria em ci√™ncia de dados, machine learning e desenvolvimento de software, fornecendo uma plataforma robusta para tomada de decis√µes baseada em dados no contexto de gest√£o de pessoas.

Este documento apresenta a arquitetura t√©cnica, metodologias aplicadas, resultados obtidos e guias de uso do sistema, servindo como refer√™ncia completa para desenvolvedores, cientistas de dados e gestores de RH que desejam compreender, utilizar ou estender a solu√ß√£o.

## 1. Vis√£o Geral do Sistema

### 1.1 Objetivos

O sistema foi desenvolvido com os seguintes objetivos principais:

**Previs√£o de Rotatividade**: Identificar funcion√°rios em risco de deixar a organiza√ß√£o atrav√©s de modelos preditivos de machine learning, permitindo a√ß√µes preventivas e proativas de reten√ß√£o de talentos.

**An√°lise Explorat√≥ria**: Fornecer insights profundos sobre os fatores que influenciam a rotatividade atrav√©s de an√°lises estat√≠sticas e visualiza√ß√µes interativas, revelando padr√µes ocultos nos dados de RH.

**Segmenta√ß√£o de Funcion√°rios**: Criar personas de funcion√°rios usando t√©cnicas de clustering n√£o supervisionado, permitindo estrat√©gias de gest√£o personalizadas para diferentes grupos com caracter√≠sticas similares.

**Dashboard Interativo**: Disponibilizar uma interface web intuitiva para explora√ß√£o de dados, visualiza√ß√£o de m√©tricas e tomada de decis√µes em tempo real, democratizando o acesso a insights de RH Analytics.

**API REST**: Oferecer endpoints program√°ticos para integra√ß√£o com outros sistemas empresariais, permitindo que as previs√µes e an√°lises sejam incorporadas em workflows existentes de RH.

### 1.2 Arquitetura do Sistema

O sistema segue uma arquitetura modular e escal√°vel, organizada em camadas bem definidas:

**Camada de Dados**: Respons√°vel pela coleta, armazenamento e prepara√ß√£o dos dados. Inclui integra√ß√£o com Supabase para persist√™ncia de previs√µes, m√©tricas e logs de execu√ß√£o, garantindo rastreabilidade e auditoria completa das opera√ß√µes.

**Camada de Processamento**: Implementa pipelines de pr√©-processamento, engenharia de features e transforma√ß√µes de dados. Utiliza t√©cnicas como normaliza√ß√£o com StandardScaler, codifica√ß√£o de vari√°veis categ√≥ricas e cria√ß√£o de features derivadas para maximizar o poder preditivo dos modelos.

**Camada de Modelagem**: Cont√©m os algoritmos de machine learning (Regress√£o Log√≠stica, Random Forest, XGBoost), t√©cnicas de balanceamento de classes (SMOTE) e otimiza√ß√£o de hiperpar√¢metros (GridSearchCV). Esta camada √© respons√°vel pelo treinamento, avalia√ß√£o e sele√ß√£o dos melhores modelos.

**Camada de Aplica√ß√£o**: Fornece interfaces de usu√°rio atrav√©s do dashboard Streamlit e endpoints de API via FastAPI. Esta camada traduz as previs√µes e an√°lises em informa√ß√µes acion√°veis para os usu√°rios finais.

**Camada de Integra√ß√£o**: Gerencia conex√µes com servi√ßos externos como Hugging Face Hub para versionamento de modelos e Supabase para armazenamento de dados, garantindo interoperabilidade e escalabilidade.

### 1.3 Tecnologias Utilizadas

O sistema foi constru√≠do utilizando um stack tecnol√≥gico moderno e amplamente adotado na ind√∫stria:

**Python 3.11**: Linguagem de programa√ß√£o principal, escolhida por sua rica biblioteca de ferramentas para ci√™ncia de dados e machine learning.

**Pandas e NumPy**: Bibliotecas fundamentais para manipula√ß√£o e an√°lise de dados tabulares, oferecendo estruturas de dados eficientes e opera√ß√µes vetorizadas.

**Scikit-learn**: Framework de machine learning que fornece implementa√ß√µes robustas de algoritmos de classifica√ß√£o, pr√©-processamento e m√©tricas de avalia√ß√£o.

**XGBoost**: Biblioteca de gradient boosting otimizada para performance, conhecida por seus excelentes resultados em competi√ß√µes de machine learning e aplica√ß√µes industriais.

**Imbalanced-learn**: Extens√£o do scikit-learn especializada em t√©cnicas de balanceamento de classes, incluindo SMOTE (Synthetic Minority Over-sampling Technique).

**Streamlit**: Framework para cria√ß√£o r√°pida de dashboards interativos e aplica√ß√µes web de dados, permitindo prototipagem √°gil e interfaces intuitivas.

**FastAPI**: Framework moderno para constru√ß√£o de APIs REST de alta performance, com valida√ß√£o autom√°tica de dados via Pydantic e documenta√ß√£o interativa autom√°tica.

**Plotly**: Biblioteca de visualiza√ß√£o interativa que permite criar gr√°ficos din√¢micos e explor√°veis, melhorando significativamente a experi√™ncia do usu√°rio.

**Supabase**: Plataforma de backend-as-a-service baseada em PostgreSQL, oferecendo banco de dados relacional, autentica√ß√£o e APIs REST/GraphQL prontas para uso.

**Hugging Face Hub**: Plataforma de versionamento e compartilhamento de modelos de machine learning, facilitando colabora√ß√£o e reprodutibilidade.

## 2. Dataset e Prepara√ß√£o de Dados

### 2.1 Descri√ß√£o do Dataset

O sistema utiliza o **Synthetic Employee Attrition Dataset**, um conjunto de dados simulado especificamente projetado para an√°lise e previs√£o de rotatividade de funcion√°rios. O dataset cont√©m **10.000 registros** de funcion√°rios fict√≠cios, com **22 features** que capturam diversos aspectos do perfil profissional e pessoal.

As features incluem informa√ß√µes demogr√°ficas (idade, g√™nero, estado civil), caracter√≠sticas profissionais (cargo, tempo de empresa, sal√°rio mensal, n√∫mero de promo√ß√µes), avalia√ß√µes subjetivas (satisfa√ß√£o no trabalho, equil√≠brio vida-trabalho, avalia√ß√£o de desempenho) e fatores contextuais (dist√¢ncia de casa, tamanho da empresa, trabalho remoto).

A vari√°vel target **Attrition** √© bin√°ria, indicando se o funcion√°rio permaneceu na empresa (0) ou saiu (1). A taxa de rotatividade no dataset √© de aproximadamente **19.5%**, refletindo um desbalanceamento de classes que √© comum em problemas reais de previs√£o de attrition.

### 2.2 Pipeline de Pr√©-processamento

O pr√©-processamento dos dados segue um pipeline sistem√°tico implementado no m√≥dulo `src/data/preprocess.py`:

**Tratamento de Valores Ausentes**: Embora o dataset sint√©tico n√£o contenha valores ausentes, o pipeline implementa estrat√©gias robustas de imputa√ß√£o. Features num√©ricas s√£o preenchidas com a mediana (mais robusta a outliers que a m√©dia), enquanto features categ√≥ricas utilizam a moda (valor mais frequente).

**Detec√ß√£o e Tratamento de Outliers**: Utiliza o m√©todo IQR (Interquartile Range) para identificar valores extremos. Outliers s√£o detectados como valores que caem abaixo de Q1 - 1.5√óIQR ou acima de Q3 + 1.5√óIQR, e s√£o substitu√≠dos pelos limites calculados (winsorization), preservando a distribui√ß√£o geral enquanto reduz o impacto de valores extremos.

**Codifica√ß√£o de Vari√°veis Categ√≥ricas**: Features ordinais (como JobSatisfaction: Very Low, Low, Medium, High) s√£o codificadas preservando a ordem natural atrav√©s de mapeamento ordinal. Features nominais (como Gender, JobRole) utilizam Label Encoding, transformando categorias em valores num√©ricos que os algoritmos de ML podem processar.

**Engenharia de Features**: Tr√™s features derivadas s√£o criadas para capturar rela√ß√µes n√£o-lineares:
- **IncomePerYearOfService**: Raz√£o entre sal√°rio mensal e tempo de empresa, indicando progress√£o salarial
- **TenureToAgeRatio**: Propor√ß√£o entre tempo de empresa e idade, revelando padr√µes de carreira
- **PromotionRate**: Taxa de promo√ß√µes por ano, medindo velocidade de crescimento profissional

**Normaliza√ß√£o**: Todas as features num√©ricas s√£o normalizadas usando StandardScaler (z-score normalization), garantindo que features com diferentes escalas tenham pesos compar√°veis nos modelos de ML.

**Divis√£o Treino-Teste**: Os dados s√£o divididos em 80% treino e 20% teste com estratifica√ß√£o pela vari√°vel target, garantindo que ambos os conjuntos mantenham a mesma propor√ß√£o de classes.

### 2.3 Balanceamento de Classes

O desbalanceamento de classes (80.5% stayed vs 19.5% left) √© tratado usando **SMOTE (Synthetic Minority Over-sampling Technique)**. Esta t√©cnica gera exemplos sint√©ticos da classe minorit√°ria atrav√©s de interpola√ß√£o entre vizinhos pr√≥ximos no espa√ßo de features, ao inv√©s de simplesmente duplicar exemplos existentes.

O SMOTE √© aplicado apenas no conjunto de treino para evitar vazamento de informa√ß√£o (data leakage), e utiliza k=5 vizinhos para gera√ß√£o de amostras sint√©ticas. Ap√≥s o balanceamento, ambas as classes t√™m aproximadamente o mesmo n√∫mero de exemplos, permitindo que os modelos aprendam padr√µes de ambas as classes de forma equilibrada.

## 3. Modelagem e Machine Learning

### 3.1 Algoritmos Implementados

O sistema implementa tr√™s algoritmos de machine learning com caracter√≠sticas complementares:

**Regress√£o Log√≠stica**: Modelo linear probabil√≠stico que serve como baseline interpret√°vel. Utiliza regulariza√ß√£o L2 (Ridge) e class_weight='balanced' para lidar com desbalanceamento. Apesar de sua simplicidade, alcan√ßou **F1-Score de 0.547** e **ROC-AUC de 0.837**, demonstrando que rela√ß√µes lineares capturam boa parte dos padr√µes de rotatividade.

**Random Forest**: Ensemble de √°rvores de decis√£o que captura rela√ß√µes n√£o-lineares e intera√ß√µes entre features. Configurado com 100 estimadores, profundidade m√°xima de 10 e class_weight='balanced'. Alcan√ßou **F1-Score de 0.540** e **ROC-AUC de 0.838**, com excelente capacidade de generaliza√ß√£o e resist√™ncia a overfitting.

**XGBoost**: Algoritmo de gradient boosting otimizado que constr√≥i √°rvores sequencialmente, corrigindo erros das √°rvores anteriores. Utiliza learning_rate=0.1, max_depth=6 e 100 estimadores. Obteve a maior **Acur√°cia (0.817)** mas menor **Recall (0.387)**, indicando foco em precis√£o ao custo de sensibilidade.

### 3.2 M√©tricas de Avalia√ß√£o

Os modelos s√£o avaliados usando m√∫ltiplas m√©tricas para capturar diferentes aspectos da performance:

**Acur√°cia**: Propor√ß√£o de previs√µes corretas. √ötil quando as classes s√£o balanceadas, mas pode ser enganosa em datasets desbalanceados.

**Precis√£o**: Propor√ß√£o de previs√µes positivas que est√£o corretas (TP / (TP + FP)). Alta precis√£o significa poucos falsos positivos, importante quando o custo de falsos alarmes √© alto.

**Recall (Sensibilidade)**: Propor√ß√£o de casos positivos reais que foram identificados (TP / (TP + FN)). Alto recall significa poucos falsos negativos, cr√≠tico quando perder casos positivos tem alto custo.

**F1-Score**: M√©dia harm√¥nica entre precis√£o e recall, balanceando ambas as m√©tricas. Escolhido como m√©trica principal para sele√ß√£o do melhor modelo, pois equilibra a capacidade de identificar funcion√°rios em risco sem gerar muitos falsos alarmes.

**ROC-AUC**: √Årea sob a curva ROC, medindo a capacidade do modelo de distinguir entre classes em diferentes thresholds. Valores pr√≥ximos a 1.0 indicam excelente discrimina√ß√£o.

### 3.3 Resultados dos Modelos

A tabela abaixo apresenta a compara√ß√£o detalhada dos tr√™s modelos:

| Modelo | Acur√°cia | Precis√£o | Recall | F1-Score | ROC-AUC |
|--------|----------|----------|--------|----------|---------|
| **Regress√£o Log√≠stica** | **0.757** | 0.429 | **0.754** | **0.547** | 0.837 |
| Random Forest | 0.796 | 0.481 | 0.615 | 0.540 | **0.838** |
| XGBoost | **0.817** | **0.543** | 0.387 | 0.452 | 0.837 |

A **Regress√£o Log√≠stica** foi selecionada como melhor modelo baseado no **F1-Score de 0.547**, que balanceia adequadamente precis√£o e recall. Seu alto recall (0.754) significa que o modelo identifica corretamente 75.4% dos funcion√°rios que realmente saem, permitindo a√ß√µes preventivas eficazes. A precis√£o de 0.429 indica que aproximadamente 43% dos alertas s√£o verdadeiros positivos, um trade-off aceit√°vel considerando o custo de perder talentos.

### 3.4 Feature Importance

A an√°lise de import√¢ncia de features revela os principais fatores que influenciam a rotatividade:

1. **Job Satisfaction (0.361)**: Satisfa√ß√£o no trabalho √© o fator mais importante, com peso 3x maior que o segundo colocado. Funcion√°rios com baixa satisfa√ß√£o t√™m probabilidade significativamente maior de sair.

2. **Work-Life Balance (0.180)**: Equil√≠brio entre vida pessoal e profissional √© o segundo fator mais relevante, destacando a import√¢ncia de pol√≠ticas de bem-estar.

3. **Number of Promotions (0.078)**: Falta de progress√£o na carreira √© um forte indicador de risco de sa√≠da, validando a import√¢ncia de planos de desenvolvimento.

4. **Performance Rating (0.054)**: Curiosamente, avalia√ß√µes de desempenho t√™m peso moderado, sugerindo que funcion√°rios de alto desempenho insatisfeitos tamb√©m saem.

5. **Monthly Income (0.053)**: Sal√°rio tem impacto menor que fatores subjetivos, indicando que compensa√ß√£o financeira sozinha n√£o ret√©m talentos.

Estes insights direcionam estrat√©gias de reten√ß√£o focadas em melhorar satisfa√ß√£o e equil√≠brio vida-trabalho, al√©m de garantir oportunidades claras de crescimento.

## 4. Dashboard Interativo

### 4.1 Arquitetura do Dashboard

O dashboard foi desenvolvido usando **Streamlit**, um framework Python que permite criar aplica√ß√µes web interativas com c√≥digo puramente Python, sem necessidade de HTML/CSS/JavaScript. A arquitetura segue o padr√£o de single-page application (SPA) com navega√ß√£o por abas, implementada atrav√©s de radio buttons no sidebar.

O dashboard utiliza **Plotly** para todas as visualiza√ß√µes, oferecendo gr√°ficos interativos com zoom, pan, hover tooltips e exporta√ß√£o de imagens. O estado da aplica√ß√£o √© gerenciado atrav√©s de decoradores `@st.cache_data` e `@st.cache_resource`, garantindo que dados e modelos sejam carregados apenas uma vez, melhorando significativamente a performance.

### 4.2 P√°ginas e Funcionalidades

O dashboard √© organizado em cinco p√°ginas principais:

**üè† Vis√£o Geral Executiva**: Apresenta KPIs de alto n√≠vel (total de funcion√°rios, taxa de rotatividade, sal√°rio m√©dio, tempo m√©dio de empresa) em cards destacados. Inclui gr√°ficos de pizza para distribui√ß√£o de attrition, gr√°ficos de barras horizontais para rotatividade por departamento, e an√°lises de tend√™ncias por faixa et√°ria e satisfa√ß√£o. Esta p√°gina fornece um snapshot r√°pido da situa√ß√£o de rotatividade na organiza√ß√£o.

**üìà An√°lise Profunda da Rotatividade**: Oferece filtros interativos por departamento, g√™nero e faixa et√°ria, permitindo an√°lises segmentadas. O destaque √© um heatmap que cruza Job Satisfaction com Work-Life Balance, revelando combina√ß√µes de alto risco. Tamb√©m exibe feature importance do modelo, ajudando gestores a entender quais fatores priorizar.

**üë• Explorador de Personas**: Apresenta a distribui√ß√£o de personas criadas por clustering K-Means, com gr√°fico de pizza mostrando propor√ß√µes. Cada persona tem um painel expans√≠vel com descri√ß√£o detalhada e recomenda√ß√µes espec√≠ficas de a√ß√µes de RH. As quatro personas identificadas s√£o:
- Riscos de Fuga de Alto Potencial (alto desempenho, baixa satisfa√ß√£o)
- Contribuidores Centrais Est√°veis (m√©dio desempenho, alta satisfa√ß√£o)
- Novos e Sobrecarregados (baixo tempo de servi√ßo, risco m√©dio-alto)
- Potencial N√£o Explorado (m√©dio-baixo desempenho, m√©dia satisfa√ß√£o)

**‚ö†Ô∏è Lista de Risco e Planejador de A√ß√µes**: Gera previs√µes para todos os funcion√°rios no conjunto de teste, classificando-os por n√≠vel de risco (alto, m√©dio, baixo). Permite filtrar por n√≠vel de risco e selecionar top N funcion√°rios. Exibe tabela com ID do funcion√°rio, n√≠vel de risco e probabilidade de rotatividade. M√©tricas agregadas mostram quantos funcion√°rios est√£o em cada categoria de risco, facilitando planejamento de recursos.

**üîÆ Fazer Previs√£o**: Ferramenta interativa para prever rotatividade de um funcion√°rio espec√≠fico. Formul√°rio com campos para idade, anos na empresa, sal√°rio, satisfa√ß√£o, work-life balance, avalia√ß√£o de desempenho, promo√ß√µes e dist√¢ncia de casa. Ao submeter, exibe probabilidade de rotatividade em gauge visual, n√≠vel de risco com emoji colorido, e lista de a√ß√µes recomendadas baseadas no n√≠vel de risco. Esta p√°gina permite que gestores avaliem rapidamente o risco de funcion√°rios individuais.

### 4.3 Guia de Uso

Para executar o dashboard localmente:

```bash
cd hr-analytics-system
streamlit run app/dashboard.py
```

O dashboard ser√° aberto automaticamente no navegador em `http://localhost:8501`. Use o menu lateral para navegar entre p√°ginas. Filtros s√£o aplicados em tempo real, e gr√°ficos s√£o totalmente interativos (zoom, pan, hover).

Para deploy em produ√ß√£o, o Streamlit oferece Streamlit Cloud gratuito, ou pode ser containerizado com Docker e deployado em qualquer plataforma de cloud (AWS, GCP, Azure, Heroku).

## 5. API REST

### 5.1 Arquitetura da API

A API foi desenvolvida usando **FastAPI**, um framework moderno de Python que oferece:
- Valida√ß√£o autom√°tica de dados via Pydantic
- Documenta√ß√£o interativa autom√°tica (Swagger UI e ReDoc)
- Alta performance compar√°vel a Node.js e Go
- Suporte nativo a async/await para opera√ß√µes ass√≠ncronas
- Type hints para melhor IDE support e detec√ß√£o de erros

A API segue princ√≠pios RESTful, com endpoints organizados por recursos (predictions, personas, metrics, model). Utiliza c√≥digos de status HTTP apropriados (200 OK, 400 Bad Request, 500 Internal Server Error) e retorna respostas em JSON estruturado.

### 5.2 Endpoints Dispon√≠veis

**GET /** - Rota raiz que retorna informa√ß√µes b√°sicas da API (nome, vers√£o, links para documenta√ß√£o).

**GET /health** - Health check endpoint que verifica se a API est√° funcionando e se o modelo est√° carregado. Retorna status "healthy" e timestamp.

**POST /predict** - Endpoint principal para previs√£o de rotatividade de um √∫nico funcion√°rio. Recebe dados do funcion√°rio no corpo da requisi√ß√£o (JSON) e retorna probabilidade de attrition, n√≠vel de risco, persona e recomenda√ß√µes. Exemplo de request:

```json
{
  "Age": 35,
  "MonthlyIncome": 8000,
  "YearsAtCompany": 5,
  "DistanceFromHome": 10,
  "NumberOfPromotions": 2,
  "JobSatisfaction_Encoded": 2,
  "WorkLifeBalance_Encoded": 2,
  "PerformanceRating_Encoded": 2,
  "Gender_Encoded": 0,
  "JobRole_Encoded": 2,
  "MaritalStatus_Encoded": 1,
  "EducationLevel_Encoded": 1
}
```

Exemplo de response:

```json
{
  "employee_id": null,
  "attrition_probability": 0.0,
  "risk_level": "low",
  "risk_label": "üü¢ Baixo",
  "persona": "Contribuidores Centrais Est√°veis",
  "recommendations": [
    "Programas de reconhecimento",
    "Iniciativas de equil√≠brio vida-trabalho",
    "Pap√©is de compartilhamento de conhecimento"
  ],
  "predicted_at": "2025-10-16T18:14:12.746467"
}
```

**POST /batch-predict** - Endpoint para previs√£o em lote de m√∫ltiplos funcion√°rios. Recebe array de objetos de funcion√°rios e retorna array de previs√µes. √ötil para processar grandes volumes de dados.

**GET /personas** - Retorna lista de todas as personas com descri√ß√µes e recomenda√ß√µes. √ötil para sistemas que precisam exibir informa√ß√µes sobre personas.

**GET /metrics** - Retorna lista de m√©tricas de RH dispon√≠veis (turnover rate, cost per hire, etc.) com descri√ß√µes e f√≥rmulas. √ötil para documenta√ß√£o e integra√ß√£o com dashboards externos.

**GET /model/info** - Retorna metadados do modelo carregado (tipo, data de treinamento, m√©tricas de performance, lista de features). √ötil para auditoria e versionamento.

### 5.3 Documenta√ß√£o Interativa

A API gera automaticamente documenta√ß√£o interativa acess√≠vel em:
- **Swagger UI**: `http://localhost:8000/docs` - Interface visual para testar endpoints
- **ReDoc**: `http://localhost:8000/redoc` - Documenta√ß√£o est√°tica mais detalhada

Ambas as interfaces permitem testar endpoints diretamente no navegador, sem necessidade de ferramentas externas como Postman.

### 5.4 Exemplo de Integra√ß√£o

Exemplo de integra√ß√£o com a API usando Python:

```python
import requests

# Endpoint da API
API_URL = "http://localhost:8000"

# Dados do funcion√°rio
employee_data = {
    "Age": 35,
    "MonthlyIncome": 8000,
    "YearsAtCompany": 5,
    "DistanceFromHome": 10,
    "NumberOfPromotions": 2,
    "JobSatisfaction_Encoded": 2,
    "WorkLifeBalance_Encoded": 2,
    "PerformanceRating_Encoded": 2,
    "Gender_Encoded": 0,
    "JobRole_Encoded": 2,
    "MaritalStatus_Encoded": 1,
    "EducationLevel_Encoded": 1
}

# Fazer previs√£o
response = requests.post(f"{API_URL}/predict", json=employee_data)
prediction = response.json()

print(f"Probabilidade de rotatividade: {prediction['attrition_probability']:.2%}")
print(f"N√≠vel de risco: {prediction['risk_label']}")
print(f"Persona: {prediction['persona']}")
print(f"Recomenda√ß√µes: {', '.join(prediction['recommendations'])}")
```

Para executar a API localmente:

```bash
cd hr-analytics-system
uvicorn src.api.main:app --reload --host 0.0.0.0 --port 8000
```

A flag `--reload` habilita hot-reload para desenvolvimento. Para produ√ß√£o, remova esta flag e considere usar Gunicorn com workers Uvicorn para melhor performance.

## 6. Integra√ß√£o com Supabase

### 6.1 Schema do Banco de Dados

O sistema utiliza Supabase (PostgreSQL) para armazenar dados operacionais. O schema inclui cinco tabelas principais:

**predictions**: Armazena previs√µes de rotatividade com employee_id, prediction_probability (0-1), persona, risk_level (high/medium/low), features usadas e timestamp. √çndices em employee_id, risk_level e predicted_at garantem queries r√°pidas.

**hr_metrics**: Registra m√©tricas de RH ao longo do tempo (turnover_rate, cost_per_hire, etc.) com metric_name, metric_value, period (e.g., "2025-10", "Q4-2025") e metadata JSON. Permite an√°lise de tend√™ncias temporais.

**execution_logs**: Logs de execu√ß√£o do sistema com action (train_model, predict, eda), status (success/error/warning), details JSON, error_message e timestamp. Essencial para debugging e auditoria.

**system_configs**: Configura√ß√µes do sistema em formato chave-valor com config_key (√∫nico), config_value (JSONB), description e timestamp. Permite configura√ß√£o din√¢mica sem redeploy.

**employee_personas**: Mapeia funcion√°rios para personas com employee_id, persona_id (0-3), persona_name, features JSON e timestamp. Permite an√°lise de distribui√ß√£o de personas e evolu√ß√£o ao longo do tempo.

Todas as tabelas utilizam BIGSERIAL para IDs, TIMESTAMP WITH TIME ZONE para timestamps e JSONB para dados semi-estruturados, aproveitando as capacidades do PostgreSQL.

### 6.2 Cliente Python

O m√≥dulo `src/data/supabase_client.py` implementa uma classe `SupabaseClient` que encapsula todas as opera√ß√µes de banco de dados:

```python
from src.data.supabase_client import get_supabase_client

# Criar cliente
client = get_supabase_client()

# Salvar previs√£o
client.save_prediction(
    employee_id=1001,
    prediction=0.85,
    persona="Riscos de Fuga de Alto Potencial",
    risk_level="high",
    features={"Age": 35, "MonthlyIncome": 8000}
)

# Recuperar previs√µes de alto risco
high_risk_predictions = client.get_predictions(risk_level="high", limit=50)

# Salvar m√©trica de RH
client.save_hr_metric(
    metric_name="turnover_rate",
    metric_value=19.5,
    period="2025-10",
    metadata={"department": "Technology"}
)

# Registrar log de execu√ß√£o
client.log_execution(
    action="train_model",
    status="success",
    details={"model": "xgboost", "f1_score": 0.88}
)
```

O cliente trata automaticamente serializa√ß√£o JSON, timestamps e erros de conex√£o, fornecendo uma interface limpa e pythonica.

### 6.3 Configura√ß√£o

Para habilitar integra√ß√£o com Supabase:

1. Crie um projeto em [https://supabase.com](https://supabase.com)
2. Execute o script SQL em `config/supabase_schema.sql` no SQL Editor do Supabase
3. Configure as vari√°veis de ambiente no `.env`:

```
SUPABASE_URL=https://seu-projeto.supabase.co
SUPABASE_KEY=sua-chave-anon
SUPABASE_SERVICE_KEY=sua-chave-service
```

4. As credenciais s√£o encontradas em Project Settings > API no painel do Supabase

## 7. Integra√ß√£o com Hugging Face

### 7.1 Versionamento de Modelos

O sistema integra com Hugging Face Hub para versionamento e compartilhamento de modelos. O m√≥dulo `src/models/huggingface_integration.py` implementa a classe `HuggingFaceModelHub`:

```python
from src.models.huggingface_integration import HuggingFaceModelHub

# Criar cliente
hf_hub = HuggingFaceModelHub(
    token="seu_token_hf",
    repo_id="seu_usuario/hr-analytics-models"
)

# Upload de todos os modelos
hf_hub.upload_all_models()

# Upload de modelo espec√≠fico
hf_hub.upload_model(
    model_path=Path("models/xgboost_model.pkl"),
    model_name="xgboost",
    metrics={"accuracy": 0.817, "f1": 0.452}
)

# Download de modelo
model_path = hf_hub.download_model("xgboost_model.pkl")
```

### 7.2 Model Cards

O sistema gera automaticamente **Model Cards** completos para cada modelo, incluindo:
- Descri√ß√£o do modelo e task
- Casos de uso pretendidos
- M√©tricas de performance
- Informa√ß√µes sobre dados de treino
- C√≥digo de exemplo para uso
- Limita√ß√µes e considera√ß√µes √©ticas
- Cita√ß√£o bibliogr√°fica

Os Model Cards seguem as melhores pr√°ticas de documenta√ß√£o de ML e s√£o essenciais para transpar√™ncia e reprodutibilidade.

### 7.3 Configura√ß√£o

Para habilitar integra√ß√£o com Hugging Face:

1. Crie uma conta em [https://huggingface.co](https://huggingface.co)
2. Gere um token em Settings > Access Tokens
3. Configure no `.env`:

```
HUGGINGFACE_TOKEN=seu_token_hf
HUGGINGFACE_REPO=seu_usuario/hr-analytics-models
```

4. Execute o script de upload:

```bash
python src/models/huggingface_integration.py
```

## 8. Guia de Instala√ß√£o e Uso

### 8.1 Pr√©-requisitos

- Python 3.11 ou superior
- pip ou poetry para gerenciamento de pacotes
- Git para controle de vers√£o
- (Opcional) Conta Supabase para persist√™ncia de dados
- (Opcional) Conta Hugging Face para versionamento de modelos

### 8.2 Instala√ß√£o

```bash
# Clonar reposit√≥rio
git clone https://github.com/SamuelMauli/hr-analytics-system.git
cd hr-analytics-system

# Criar ambiente virtual
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate  # Windows

# Instalar depend√™ncias
pip install -r requirements.txt

# Configurar vari√°veis de ambiente
cp .env.example .env
# Edite .env com suas credenciais
```

### 8.3 Execu√ß√£o

**Baixar/Criar Dataset**:
```bash
python src/data/download_dataset.py
```

**Pr√©-processar Dados**:
```bash
python src/data/preprocess.py
```

**Treinar Modelos**:
```bash
python src/models/train_models.py
```

**Executar Dashboard**:
```bash
streamlit run app/dashboard.py
```

**Executar API**:
```bash
uvicorn src.api.main:app --reload
```

**Executar Notebook de EDA**:
```bash
jupyter notebook notebooks/01_exploratory_data_analysis.ipynb
```

## 9. Considera√ß√µes √âticas e Limita√ß√µes

### 9.1 Privacidade e LGPD/GDPR

O sistema lida com dados sens√≠veis de funcion√°rios, exigindo conformidade com LGPD (Brasil) e GDPR (Europa). Recomenda√ß√µes:

- **Anonimiza√ß√£o**: Remover ou hash de identificadores pessoais (nome, CPF, email) antes de an√°lise
- **Minimiza√ß√£o de Dados**: Coletar apenas features estritamente necess√°rias para previs√£o
- **Consentimento**: Obter consentimento expl√≠cito dos funcion√°rios para uso de seus dados
- **Direito ao Esquecimento**: Implementar mecanismos para deletar dados de funcion√°rios que solicitarem
- **Auditoria**: Manter logs de acesso e uso de dados para rastreabilidade

### 9.2 Vi√©s Algor√≠tmico

Modelos de ML podem perpetuar ou amplificar vieses presentes nos dados de treino. Mitiga√ß√µes:

- **An√°lise de Fairness**: Avaliar m√©tricas de performance separadamente por g√™nero, idade, etnia
- **Monitoramento Cont√≠nuo**: Acompanhar se o modelo est√° fazendo previs√µes enviesadas para certos grupos
- **Transpar√™ncia**: Documentar claramente quais features s√£o usadas e como influenciam previs√µes
- **Revis√£o Humana**: Garantir que decis√µes cr√≠ticas (demiss√µes, promo√ß√µes) n√£o sejam baseadas apenas no modelo

### 9.3 Limita√ß√µes do Sistema

**Dados Sint√©ticos**: O sistema foi treinado com dados simulados, n√£o reais. Performance em dados reais pode variar significativamente.

**Generaliza√ß√£o**: Modelos treinados em uma organiza√ß√£o podem n√£o generalizar bem para outras com culturas e din√¢micas diferentes.

**Causalidade vs Correla√ß√£o**: O modelo identifica correla√ß√µes, n√£o causas. Uma feature importante n√£o necessariamente causa rotatividade.

**Fatores Externos**: O modelo n√£o captura fatores externos como condi√ß√µes de mercado, oportunidades em outras empresas, mudan√ßas pessoais.

**Atualiza√ß√£o**: Modelos devem ser retreinados periodicamente (recomendado: trimestral ou semestral) para capturar mudan√ßas nas din√¢micas de rotatividade.

## 10. Pr√≥ximos Passos e Melhorias Futuras

### 10.1 Melhorias T√©cnicas

- **Modelos Avan√ßados**: Testar redes neurais (MLP, LSTM para dados temporais), LightGBM, CatBoost
- **AutoML**: Implementar pipelines de AutoML (H2O.ai, TPOT) para otimiza√ß√£o autom√°tica
- **Explicabilidade**: Adicionar SHAP values e LIME para explicar previs√µes individuais
- **Monitoramento de Drift**: Detectar quando distribui√ß√£o de dados muda (concept drift, data drift)
- **A/B Testing**: Framework para testar diferentes modelos em produ√ß√£o

### 10.2 Novas Funcionalidades

- **An√°lise de Sentimento**: Processar feedbacks de texto (pesquisas, entrevistas de desligamento) com NLP
- **S√©ries Temporais**: Prever tend√™ncias futuras de rotatividade usando ARIMA, Prophet
- **Recomenda√ß√µes Personalizadas**: Sistema de recomenda√ß√£o de a√ß√µes de reten√ß√£o por funcion√°rio
- **Simula√ß√£o de Cen√°rios**: "What-if analysis" para avaliar impacto de mudan√ßas (aumento salarial, promo√ß√µes)
- **Integra√ß√£o com HRIS**: Conectar com sistemas de RH existentes (SAP SuccessFactors, Workday, Oracle HCM)

### 10.3 Escalabilidade

- **Containeriza√ß√£o**: Dockerizar aplica√ß√£o para deploy consistente
- **Orquestra√ß√£o**: Usar Kubernetes para escalar horizontalmente
- **Cache Distribu√≠do**: Redis para cache de previs√µes e dados frequentes
- **Processamento em Lote**: Apache Spark para processar grandes volumes de dados
- **CI/CD**: Pipeline automatizado de testes, build e deploy

## 11. Conclus√£o

O Sistema de HR Analytics desenvolvido representa uma solu√ß√£o completa e robusta para an√°lise preditiva de rotatividade de funcion√°rios. Atrav√©s da combina√ß√£o de t√©cnicas modernas de machine learning, engenharia de dados e desenvolvimento de software, o sistema fornece insights acion√°veis que podem transformar a gest√£o de pessoas em organiza√ß√µes.

Os resultados obtidos demonstram que √© poss√≠vel prever rotatividade com acur√°cia superior a 75% usando dados estruturados de RH, permitindo que gestores identifiquem funcion√°rios em risco e tomem a√ß√µes preventivas. A identifica√ß√£o de Job Satisfaction e Work-Life Balance como fatores mais importantes direciona investimentos em programas de bem-estar e engajamento.

O sistema foi projetado com extensibilidade e escalabilidade em mente, permitindo f√°cil integra√ß√£o com sistemas existentes atrav√©s da API REST, e evolu√ß√£o cont√≠nua atrav√©s de modulariza√ß√£o clara e versionamento de modelos. A documenta√ß√£o completa e c√≥digo bem estruturado facilitam manuten√ß√£o e colabora√ß√£o.

Acima de tudo, o sistema foi desenvolvido com consci√™ncia √©tica, reconhecendo as responsabilidades envolvidas no uso de dados de funcion√°rios e machine learning em decis√µes de RH. O uso respons√°vel, transparente e com supervis√£o humana √© fundamental para que a tecnologia sirva como ferramenta de empoderamento, n√£o de discrimina√ß√£o.

## Refer√™ncias

1. Synthetic Employee Attrition Dataset - Kaggle. Dispon√≠vel em: [https://www.kaggle.com/datasets/stealthtechnologies/employee-attrition-dataset](https://www.kaggle.com/datasets/stealthtechnologies/employee-attrition-dataset)

2. Scikit-learn Documentation. Dispon√≠vel em: [https://scikit-learn.org/stable/](https://scikit-learn.org/stable/)

3. XGBoost Documentation. Dispon√≠vel em: [https://xgboost.readthedocs.io/](https://xgboost.readthedocs.io/)

4. SMOTE: Synthetic Minority Over-sampling Technique - Chawla et al., 2002. Journal of Artificial Intelligence Research.

5. Streamlit Documentation. Dispon√≠vel em: [https://docs.streamlit.io/](https://docs.streamlit.io/)

6. FastAPI Documentation. Dispon√≠vel em: [https://fastapi.tiangolo.com/](https://fastapi.tiangolo.com/)

7. Supabase Documentation. Dispon√≠vel em: [https://supabase.com/docs](https://supabase.com/docs)

8. Hugging Face Hub Documentation. Dispon√≠vel em: [https://huggingface.co/docs/hub](https://huggingface.co/docs/hub)

9. HR Analytics: A Comprehensive Guide - Leapsome. Dispon√≠vel em: [https://www.leapsome.com/blog/hr-analytics-guide](https://www.leapsome.com/blog/hr-analytics-guide)

10. Machine Learning Models for Predicting Employee Attrition: A Data Science Perspective - ResearchGate, 2025.

---

**Autor**: Manus AI  
**Data**: 16 de outubro de 2025  
**Vers√£o**: 1.0.0  
**Reposit√≥rio**: [https://github.com/SamuelMauli/hr-analytics-system](https://github.com/SamuelMauli/hr-analytics-system)

